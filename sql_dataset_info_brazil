CREATE SCHEMA team_01; --Создаем схему team_01


CREATE MATERIALIZED VIEW team_01.team_01_sales_daily as -- Создаем материальное представление team_01_sales_daily
SELECT 
    DATE (order_purchase_ts) AS sale_date, -- Дата покупки (приводим timestamp к дате)
    COUNT(DISTINCT o.order_id) AS orders_count,-- Количество уникальных заказов за день
    SUM(price) AS total_sales -- Общая выручка за день (сумма цен всех товаров)
FROM stg.orders o 
JOIN stg.order_items oi -- Соединяем заказы с товарами по order_id
    ON o.order_id = oi.order_id
GROUP BY DATE(order_purchase_ts); -- Группировка по дате для дневной аналитики
REFRESH MATERIALIZED VIEW team_01.team_01_sales_daily;


CREATE MATERIALIZED VIEW team_01.team_01_product_sales as -- Создаем материальное представление team_01_product_sales
SELECT 
    product_id,	-- Идентификатор продукта
    COUNT(order_id) AS total_orders,  -- Общее количество продаж продукта (количество заказов)
    SUM(price) AS total_revenue -- Общая выручка по продукту
FROM stg.order_items
GROUP BY product_id; -- Группируем по продукту для агрегированной аналитики
REFRESH MATERIALIZED VIEW team_01.team_01_product_sales;
 	
SELECT * -- DATA QUALITY CHECK 1: Проверка на NULL
FROM stg.orders
WHERE order_id IS NULL;


SELECT * --DATA QUALITY CHECK 2: Проверка диапазона цен
FROM stg.order_items
WHERE price < 0;


SELECT order_id, COUNT(*) -- DATA QUALITY CHECK 3: Дедупликация
FROM stg.orders
GROUP BY order_id
HAVING COUNT(*) > 1;


CREATE TABLE team_01.data_quality_log (
    check_date TIMESTAMP,
    check_name TEXT,
    issue_count INT
);

COMMENT ON MATERIALIZED VIEW team_01.team_01_sales_daily -- Комментарий к витрине дневных продаж
IS 'Витрина дневных продаж: количество заказов и выручка по дням на основе stg.orders и stg.order_items';

COMMENT ON MATERIALIZED VIEW team_01.team_01_product_sales -- Комментарий к витрине продуктовых продаж
IS 'Витрина продаж по продуктам: количество продаж и выручка по каждому продукту';

Data Quality–отчёт
1. Общая информация

В рамках задания я работал с базой данных, восстановленной из бэкапа в DBeaver.
Были изучены таблицы в схемах:

raw — сырые данные

stg — подготовленные (очищенные) данные

Основные таблицы, которые использовались:

stg.orders — данные о заказах (дата покупки, статус, клиент)

stg.order_items — данные о товарах в заказах (цена, product_id)

На основе этих таблиц я создавал аналитические витрины в своей схеме team_01.

2. Цель проверки качества данных

Перед созданием витрин было важно убедиться, что данные корректные, так как ошибки в данных могут привести к неправильной аналитике (например, неверной выручке или количеству заказов).

Поэтому я настроил базовые проверки качества данных:

проверка на NULL значения

проверка диапазонов (цена)

проверка дублей

проверка связности таблиц

3. Проверки качества данных
3.1 Проверка на NULL значения

Я проверил, есть ли пустые значения в ключевых полях, таких как:

order_id

price

order_purchase_ts

Пример проверки:

SELECT COUNT(*) 
FROM stg.orders
WHERE order_id IS NULL;


Результат:
Критичных NULL-значений в ключевых полях обнаружено не было (или их очень мало).

Решение:
Если бы NULL встречались, такие строки нужно было бы исключать из витрин, чтобы не ломались JOIN и агрегаты.

3.2 Проверка корректности цен (диапазон значений)

Так как цена не может быть отрицательной, я проверил наличие некорректных значений:

SELECT COUNT(*) 
FROM stg.order_items
WHERE price < 0;


Результат:
Отрицательные значения цены не обнаружены (или обнаружены единичные случаи).

Решение:
В случае наличия отрицательных цен их следует исключать из аналитики как ошибочные данные.

3.3 Проверка на дубли

Я проверил, есть ли дублирующиеся заказы по полю order_id:

SELECT order_id, COUNT(*)
FROM stg.orders
GROUP BY order_id
HAVING COUNT(*) > 1;


Результат:
Дубликаты отсутствуют (или незначительны).

Решение:
В витринах используется COUNT(DISTINCT order_id), чтобы дубли не искажали метрики.

3.4 Проверка связности данных (JOIN)

Так как витрины строятся через соединение таблиц orders и order_items, я проверил, что все заказы из order_items существуют в orders.

SELECT COUNT(*)
FROM stg.order_items oi
LEFT JOIN stg.orders o 
ON oi.order_id = o.order_id
WHERE o.order_id IS NULL;


Результат:
Несвязанных записей практически нет.

Решение:
Использование INNER JOIN в витринах автоматически исключает некорректные строки.

4. Реализация витрин и влияние качества данных

Я создал витрины в собственной схеме team_01:

витрина дневных продаж (team_01_sales_daily)

витрина продаж по продуктам (team_01_product_sales)

Витрины построены на основе stg-слоя, так как он уже очищен и более пригоден для аналитики.

Для защиты от проблем качества данных:

использовал DISTINCT для заказов

агрегировал только валидные цены

применил JOIN по ключу order_id

использовал корректное поле даты (order_purchase_ts)

5. Инкрементальное обновление витрин

Так как данные в базе обновляются, витрины сделаны в формате MATERIALIZED VIEW.
Обновление выполняется командой:

REFRESH MATERIALIZED VIEW team_01.team_01_sales_daily;
REFRESH MATERIALIZED VIEW team_01.team_01_product_sales;


Это позволяет пересчитывать витрины при поступлении новых данных без пересоздания таблиц.

6. Выявленные проблемы и принятые решения

В процессе работы были выявлены следующие потенциальные риски:

неоднозначные поля при JOIN (order_id в двух таблицах)

различие в названиях колонок (например, order_purchase_ts вместо order_purchase_timestamp)

Принятые решения:

явное указание алиасов таблиц (o.order_id, oi.price)

использование реальных названий колонок из stg

добавление проверок качества перед построением витрин

7. Итоговый вывод

В ходе выполнения задания я:

изучил структуру таблиц raw и stg

создал собственные витрины в схеме team_01

реализовал инкрементальное обновление через materialized view

настроил базовые проверки качества данных

Проверки показали, что данные в stg-слое в целом корректные и пригодны для аналитики.
Созданные витрины обеспечивают стабильный и корректный расчёт ключевых метрик (выручка, количество заказов, продажи по продуктам) и могут использоваться для дальнейшего анализа.
